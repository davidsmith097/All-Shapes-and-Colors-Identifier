{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383c140c",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa430e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import cv2\n",
    "# Pytorch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46631f",
   "metadata": {},
   "source": [
    "# Prep Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a793b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# square = 0, circle = 1, triangle = 2\n",
    "# red = 0, green = 1, blue = 2\n",
    "LABELS = ['square', 'circle', 'triangle', 'NONE']\n",
    "COLORS = ['red', 'green', 'blue', 'NONE']\n",
    "\n",
    "def customCollate(batch):\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "\n",
    "    shapes = torch.stack([item[1][\"shape\"] for item in batch])\n",
    "    colors = torch.stack([item[1][\"color\"] for item in batch])\n",
    "\n",
    "    label_dict = {\"shape\": shapes, \"color\": colors}\n",
    "    return images, label_dict\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_dir, label_csv, transform=transforms.ToTensor(), max_shapes=10):\n",
    "        self.max_shapes = max_shapes\n",
    "        self.transform = transform\n",
    "        self.label_to_num = {\"square\" : 0, \"circle\" : 1, \"triangle\" : 2}\n",
    "        self.color_to_num = {\"red\" : 0, \"green\" : 1, \"blue\" : 2}\n",
    "        self.img_filenames = []\n",
    "        self.img_labels = []\n",
    "        for img in os.listdir(input_dir):\n",
    "            self.img_filenames.append(os.path.join(input_dir, img))\n",
    "        with open(label_csv, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            first = True\n",
    "            for row in reader:\n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue\n",
    "                self.img_labels.append(ast.literal_eval(row[1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.img_filenames[idx]\n",
    "        get_labels = self.img_labels[idx]\n",
    "\n",
    "        image = cv2.imread(img_filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        shape_list = []\n",
    "        color_list = []\n",
    "        for i in range(self.max_shapes):\n",
    "            if i < len(get_labels):\n",
    "                shape, col = get_labels[i]\n",
    "                shape_list.append(self.label_to_num[shape])\n",
    "                color_list.append(self.color_to_num[col])\n",
    "            else:\n",
    "                shape_list.append(3)\n",
    "                color_list.append(3)\n",
    "        label_dict = {\"shape\": torch.from_numpy(np.array(shape_list)), \"color\": torch.from_numpy(np.array(color_list))}\n",
    "\n",
    "        return image, label_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d4d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(r\"dataset_v3\\train_dataset\", r\"dataset_v3\\train.csv\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, collate_fn=customCollate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093d4cb",
   "metadata": {},
   "source": [
    "# Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f324c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(pred, labels):\n",
    "    pred_shapes = pred[\"shape\"]\n",
    "    pred_colors = pred[\"color\"]\n",
    "    label_shapes = labels[\"shape\"]\n",
    "    label_colors = labels[\"color\"]\n",
    "\n",
    "    criterion_shape = nn.CrossEntropyLoss()\n",
    "    criterion_color = nn.CrossEntropyLoss()\n",
    "\n",
    "    shape_loss = criterion_shape(pred_shapes.reshape(-1, 4), label_shapes.reshape(-1))\n",
    "    color_loss = criterion_color(pred_colors.reshape(-1, 4), label_colors.reshape(-1))\n",
    "\n",
    "    return (shape_loss + color_loss) / 2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cbc1a",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675fab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeColorModel(nn.Module):\n",
    "    def __init__(self, max_shapes=10):\n",
    "        super().__init__()\n",
    "        self.max_shapes = max_shapes\n",
    "\n",
    "        # Get resnet50 but remove the last layer \n",
    "        self.backbone = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "        # To get output size (batch, 2048)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone_dim = 2048\n",
    "\n",
    "        # One head to predict each of shape and color\n",
    "        self.color_head = nn.Linear(self.backbone_dim, self.max_shapes * 4)\n",
    "        self.shape_head = nn.Linear(self.backbone_dim, self.max_shapes * 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "    \n",
    "        # Get shape and color preds for each slot\n",
    "        out_shape = self.shape_head(features).view(-1, self.max_shapes, 4) # Get to shape (batch_size, max_shapes, 4)\n",
    "        out_color = self.color_head(features).view(-1, self.max_shapes, 4) # Get to shape (batch_size, max_shapes, 4)\n",
    "\n",
    "        return {\"shape\" : out_shape, \"color\" : out_color}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa89ac",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815dc831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Entering batches\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "model = ShapeColorModel()\n",
    "model.cuda()\n",
    "\n",
    "print(next(model.shape_head.parameters()).device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = []\n",
    "    print(\"Entering batches\")\n",
    "    for i, (batch, labels) in enumerate(train_dataloader):\n",
    "        print(\"Starting batch to cuda\")\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        print(\"Done with batch loading\")\n",
    "        labels = {k: v.to(device, non_blocking=True) for k, v in labels.items()}\n",
    "\n",
    "        print(\"Forward pass\")\n",
    "        pred = model(batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = customLoss(pred, labels)\n",
    "        print(\"Post loss\")\n",
    "        loss.backward()\n",
    "        print(\"Post backward pass\")\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss.append(loss)\n",
    "\n",
    "    print(f\"Avg Epoch Loss: {sum(epoch_loss) / len(epoch_loss)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
