{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383c140c",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa430e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import cv2\n",
    "import pandas as pd\n",
    "# Pytorch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46631f",
   "metadata": {},
   "source": [
    "# Prep Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a793b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# square = 0, circle = 1, triangle = 2\n",
    "# red = 0, green = 1, blue = 2\n",
    "LABELS = ['square', 'circle', 'triangle', 'NONE']\n",
    "COLORS = ['red', 'green', 'blue', 'NONE']\n",
    "\n",
    "def customCollate(batch):\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "\n",
    "    shapes = torch.stack([item[1][\"shape\"] for item in batch])\n",
    "    colors = torch.stack([item[1][\"color\"] for item in batch])\n",
    "\n",
    "    label_dict = {\"shape\": shapes, \"color\": colors}\n",
    "    return images, label_dict\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_dir, label_csv, transform=transforms.ToTensor(), max_shapes=10):\n",
    "        self.max_shapes = max_shapes\n",
    "        self.transform = transform\n",
    "        self.label_to_num = {\"square\" : 0, \"circle\" : 1, \"triangle\" : 2}\n",
    "        self.color_to_num = {\"red\" : 0, \"green\" : 1, \"blue\" : 2}\n",
    "        self.img_filenames = []\n",
    "        self.img_labels = []\n",
    "        \n",
    "        files = os.listdir(input_dir)\n",
    "        files = sorted(files, key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n",
    "        for img in files:\n",
    "            self.img_filenames.append(os.path.join(input_dir, img))\n",
    "        with open(label_csv, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            first = True\n",
    "            for row in reader:\n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue\n",
    "                self.img_labels.append(ast.literal_eval(row[1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.img_filenames[idx]\n",
    "        get_labels = self.img_labels[idx]\n",
    "\n",
    "        image = cv2.imread(img_filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        shape_list = []\n",
    "        color_list = []\n",
    "        for i in range(self.max_shapes):\n",
    "            if i < len(get_labels):\n",
    "                shape, col = get_labels[i]\n",
    "                shape_list.append(self.label_to_num[shape])\n",
    "                color_list.append(self.color_to_num[col])\n",
    "            else:\n",
    "                shape_list.append(3)\n",
    "                color_list.append(3)\n",
    "        label_dict = {\"shape\": torch.from_numpy(np.array(shape_list)), \"color\": torch.from_numpy(np.array(color_list))}\n",
    "\n",
    "        return image, label_dict\n",
    "\n",
    "class CustomTestSet(Dataset):\n",
    "    def __init__(self, input_dir, transform=transforms.ToTensor(), max_shapes=10):\n",
    "        self.image_dir = input_dir\n",
    "        self.max_shapes = max_shapes\n",
    "        self.transform = transform\n",
    "        self.img_filenames = []\n",
    "        \n",
    "        files = os.listdir(input_dir)\n",
    "        files = sorted(files, key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n",
    "        for img in files:\n",
    "            self.img_filenames.append(os.path.join(input_dir, img))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.img_filenames[idx]\n",
    "\n",
    "        image = cv2.imread(img_filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        relative_path = os.path.relpath(img_filename, start=self.image_dir)\n",
    "        relative_path = relative_path.replace(\"\\\\\", \"/\")\n",
    "        relative_path = f\"test_dataset/{relative_path}\"\n",
    "\n",
    "        return image, relative_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9d4d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(r\"dataset_v3\\train_dataset\", r\"dataset_v3\\train.csv\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=customCollate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093d4cb",
   "metadata": {},
   "source": [
    "# Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f324c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(pred, labels):\n",
    "    pred_shapes = pred[\"shape\"]\n",
    "    pred_colors = pred[\"color\"]\n",
    "    label_shapes = labels[\"shape\"]\n",
    "    label_colors = labels[\"color\"]\n",
    "\n",
    "    criterion_shape = nn.CrossEntropyLoss()\n",
    "    criterion_color = nn.CrossEntropyLoss()\n",
    "\n",
    "    shape_loss = criterion_shape(pred_shapes.reshape(-1, 4), label_shapes.reshape(-1))\n",
    "    color_loss = criterion_color(pred_colors.reshape(-1, 4), label_colors.reshape(-1))\n",
    "\n",
    "    return (shape_loss + color_loss) / 2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cbc1a",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaimingInitWeights(seq_layer):\n",
    "    if isinstance(seq_layer, nn.Linear):\n",
    "        nn.init.kaiming_normal_(seq_layer.weight, nonlinearity='relu')\n",
    "        if seq_layer.bias is not None:\n",
    "            nn.init.constant_(seq_layer.bias, 0)\n",
    "\n",
    "\n",
    "class ShapeColorModel(nn.Module):\n",
    "    def __init__(self, max_shapes=10):\n",
    "        super().__init__()\n",
    "        self.max_shapes = max_shapes\n",
    "\n",
    "        # Get resnet50 but remove the last layer \n",
    "        self.backbone = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "        # To get output size (batch, 2048)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone_dim = 2048\n",
    "\n",
    "        # One head to predict each of shape and color\n",
    "        self.shape_head = nn.Sequential(\n",
    "            nn.Linear(self.backbone_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.max_shapes * 4)\n",
    "        )\n",
    "\n",
    "        self.color_head = nn.Sequential(\n",
    "            nn.Linear(self.backbone_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.max_shapes * 4)\n",
    "        )\n",
    "        \n",
    "        self.shape_head.apply(kaimingInitWeights)\n",
    "        self.color_head.apply(kaimingInitWeights)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "    \n",
    "        # Get shape and color preds for each slot\n",
    "        out_shape = self.shape_head(features).view(-1, self.max_shapes, 4) # Get to shape (batch_size, max_shapes, 4)\n",
    "        out_color = self.color_head(features).view(-1, self.max_shapes, 4) # Get to shape (batch_size, max_shapes, 4)\n",
    "\n",
    "        return {\"shape\" : out_shape, \"color\" : out_color}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa89ac",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "815dc831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Avg Epoch Loss: 0.168692484498024\n",
      "Avg Epoch Loss: 0.07702013850212097\n",
      "Avg Epoch Loss: 0.06421952694654465\n",
      "Avg Epoch Loss: 0.05819423496723175\n",
      "Avg Epoch Loss: 0.05389714241027832\n",
      "Avg Epoch Loss: 0.04817719757556915\n",
      "Avg Epoch Loss: 0.06601420044898987\n",
      "Avg Epoch Loss: 0.04684426262974739\n",
      "Avg Epoch Loss: 0.04212377220392227\n",
      "Avg Epoch Loss: 0.03737744688987732\n",
      "Avg Epoch Loss: 0.03427338972687721\n",
      "Avg Epoch Loss: 0.03379887342453003\n",
      "Avg Epoch Loss: 0.03246501088142395\n",
      "Avg Epoch Loss: 0.03112662024796009\n",
      "Avg Epoch Loss: 0.03348517790436745\n",
      "Avg Epoch Loss: 0.022238869220018387\n",
      "Avg Epoch Loss: 0.013855098746716976\n",
      "Avg Epoch Loss: 0.013589863665401936\n",
      "Avg Epoch Loss: 0.02160891890525818\n",
      "Avg Epoch Loss: 0.009305385872721672\n",
      "Avg Epoch Loss: 0.007834656164050102\n",
      "Avg Epoch Loss: 0.004741713870316744\n",
      "Avg Epoch Loss: 0.0030881718266755342\n",
      "Avg Epoch Loss: 0.0018660166533663869\n",
      "Avg Epoch Loss: 0.0013848316157236695\n",
      "Avg Epoch Loss: 0.00436432333663106\n",
      "Avg Epoch Loss: 0.0016415377613157034\n",
      "Avg Epoch Loss: 0.0006312510231509805\n",
      "Avg Epoch Loss: 0.0003683523100335151\n",
      "Avg Epoch Loss: 0.0003393886727280915\n",
      "Avg Epoch Loss: 9.561775368638337e-05\n",
      "Avg Epoch Loss: 7.116999040590599e-05\n",
      "Avg Epoch Loss: 5.402526949183084e-05\n",
      "Avg Epoch Loss: 3.8666454202029854e-05\n",
      "Avg Epoch Loss: 3.2107665902003646e-05\n",
      "Avg Epoch Loss: 2.901452717196662e-05\n",
      "Avg Epoch Loss: 2.483506796124857e-05\n",
      "Avg Epoch Loss: 2.201315510319546e-05\n",
      "Avg Epoch Loss: 2.5102344807237387e-05\n",
      "Avg Epoch Loss: 4.509425343712792e-05\n",
      "Avg Epoch Loss: 2.597046477603726e-05\n",
      "Avg Epoch Loss: 2.151549961126875e-05\n",
      "Avg Epoch Loss: 2.0876235794276e-05\n",
      "Avg Epoch Loss: 1.8789916794048622e-05\n",
      "Avg Epoch Loss: 1.9703784346347675e-05\n",
      "Avg Epoch Loss: 1.5600380720570683e-05\n",
      "Avg Epoch Loss: 1.5999195966287516e-05\n",
      "Avg Epoch Loss: 1.8813299902831204e-05\n",
      "Avg Epoch Loss: 1.8371913029113784e-05\n",
      "Avg Epoch Loss: 1.5030986105557531e-05\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "\n",
    "model = ShapeColorModel()\n",
    "model.cuda()\n",
    "\n",
    "print(next(model.shape_head.parameters()).device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=0.00001)\n",
    "\n",
    "model.train()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = []\n",
    "    # print(\"Entering batches\")\n",
    "    for i, (batch, labels) in enumerate(train_dataloader):\n",
    "        # print(\"Starting batch to cuda\")\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        # print(\"Done with batch loading\")\n",
    "        labels = {k: v.to(device, non_blocking=True) for k, v in labels.items()}\n",
    "\n",
    "        # print(\"Forward pass\")\n",
    "        pred = model(batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = customLoss(pred, labels)\n",
    "        # print(\"Post loss\")\n",
    "        loss.backward()\n",
    "        # print(\"Post backward pass\")\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss.append(loss)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Avg Epoch Loss: {sum(epoch_loss) / len(epoch_loss)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233035e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1312dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomTestSet(r\"dataset_v3\\test_dataset\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i, (batch, label) in enumerate(test_dataloader):\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "\n",
    "        pred = model(batch)\n",
    "        shape_preds = pred[\"shape\"].squeeze(0).argmax(dim=1)\n",
    "        color_preds = pred[\"color\"].squeeze(0).argmax(dim=1)\n",
    "\n",
    "        shape_preds = shape_preds.cpu().numpy()\n",
    "        color_preds = color_preds.cpu().numpy()\n",
    "\n",
    "        label_list = []\n",
    "        for shape, color in zip(shape_preds, color_preds):\n",
    "                if shape == 3 or color == 3:\n",
    "                        continue\n",
    "                if (LABELS[shape], COLORS[color]) in label_list:\n",
    "                      continue\n",
    "                label_list.append((LABELS[shape], COLORS[color]))\n",
    "        predictions.append((label, str(label_list)))\n",
    "\n",
    "with open(\"test_predictions.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow([\"img_path\", \"label\"])\n",
    "    for filename, label_string in predictions:\n",
    "        writer.writerow([filename[0], label_string])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
